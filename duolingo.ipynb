{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "minor-glossary",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "adjacent-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "import time\n",
    "import math\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-romania",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "composite-enforcement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_recall</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>delta</th>\n",
       "      <th>user_id</th>\n",
       "      <th>learning_language</th>\n",
       "      <th>ui_language</th>\n",
       "      <th>lexeme_id</th>\n",
       "      <th>lexeme_string</th>\n",
       "      <th>history_seen</th>\n",
       "      <th>history_correct</th>\n",
       "      <th>session_seen</th>\n",
       "      <th>session_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>1052c3ace653dbc8923eaa183bc02b88</td>\n",
       "      <td>definition/definition&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>9cba1b30f88bf3c047b22cffcaf88c12</td>\n",
       "      <td>surface/surface&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>961cd149f20f2571419b1412d849f19a</td>\n",
       "      <td>scale/scale&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>5cbb1249562e95794a4c4ae0e2d8ae26</td>\n",
       "      <td>temperature/temperature&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>44</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>2df65bdf80d10d2b78d62cb2e0a731d8</td>\n",
       "      <td>distance/distance&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p_recall   timestamp  delta user_id learning_language ui_language  \\\n",
       "87       1.0  1362082504    357  u:dwbJ                en          pt   \n",
       "88       1.0  1362082504    357  u:dwbJ                en          pt   \n",
       "89       1.0  1362082504    357  u:dwbJ                en          pt   \n",
       "90       0.8  1362082504    357  u:dwbJ                en          pt   \n",
       "91       1.0  1362082504    357  u:dwbJ                en          pt   \n",
       "\n",
       "                           lexeme_id                   lexeme_string  \\\n",
       "87  1052c3ace653dbc8923eaa183bc02b88    definition/definition<n><sg>   \n",
       "88  9cba1b30f88bf3c047b22cffcaf88c12          surface/surface<n><sg>   \n",
       "89  961cd149f20f2571419b1412d849f19a              scale/scale<n><sg>   \n",
       "90  5cbb1249562e95794a4c4ae0e2d8ae26  temperature/temperature<n><sg>   \n",
       "91  2df65bdf80d10d2b78d62cb2e0a731d8        distance/distance<n><sg>   \n",
       "\n",
       "    history_seen  history_correct  session_seen  session_correct  \n",
       "87            17               17             2                2  \n",
       "88            19               19             3                3  \n",
       "89            21               20             3                3  \n",
       "90            44               36             5                4  \n",
       "91            21               20             3                3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duolingo_dataset = pd.read_csv(\"./settles.acl16.learning_traces.13m.csv\")\n",
    "duolingo_dataset = duolingo_dataset[duolingo_dataset[\"learning_language\"] == \"en\"]\n",
    "duolingo_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-guard",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "marked-relationship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_recall</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>delta</th>\n",
       "      <th>user_id</th>\n",
       "      <th>learning_language</th>\n",
       "      <th>ui_language</th>\n",
       "      <th>lexeme_id</th>\n",
       "      <th>lexeme_string</th>\n",
       "      <th>history_seen</th>\n",
       "      <th>history_correct</th>\n",
       "      <th>session_seen</th>\n",
       "      <th>session_correct</th>\n",
       "      <th>history_right</th>\n",
       "      <th>history_wrong</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>1052c3ace653dbc8923eaa183bc02b88</td>\n",
       "      <td>definition/definition&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>9cba1b30f88bf3c047b22cffcaf88c12</td>\n",
       "      <td>surface/surface&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>961cd149f20f2571419b1412d849f19a</td>\n",
       "      <td>scale/scale&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.582576</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.004132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>5cbb1249562e95794a4c4ae0e2d8ae26</td>\n",
       "      <td>temperature/temperature&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>44</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6.082763</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.004132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>2df65bdf80d10d2b78d62cb2e0a731d8</td>\n",
       "      <td>distance/distance&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.582576</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.004132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p_recall   timestamp  delta user_id learning_language ui_language  \\\n",
       "87       1.0  1362082504    357  u:dwbJ                en          pt   \n",
       "88       1.0  1362082504    357  u:dwbJ                en          pt   \n",
       "89       1.0  1362082504    357  u:dwbJ                en          pt   \n",
       "90       0.8  1362082504    357  u:dwbJ                en          pt   \n",
       "91       1.0  1362082504    357  u:dwbJ                en          pt   \n",
       "\n",
       "                           lexeme_id                   lexeme_string  \\\n",
       "87  1052c3ace653dbc8923eaa183bc02b88    definition/definition<n><sg>   \n",
       "88  9cba1b30f88bf3c047b22cffcaf88c12          surface/surface<n><sg>   \n",
       "89  961cd149f20f2571419b1412d849f19a              scale/scale<n><sg>   \n",
       "90  5cbb1249562e95794a4c4ae0e2d8ae26  temperature/temperature<n><sg>   \n",
       "91  2df65bdf80d10d2b78d62cb2e0a731d8        distance/distance<n><sg>   \n",
       "\n",
       "    history_seen  history_correct  session_seen  session_correct  \\\n",
       "87            17               17             2                2   \n",
       "88            19               19             3                3   \n",
       "89            21               20             3                3   \n",
       "90            44               36             5                4   \n",
       "91            21               20             3                3   \n",
       "\n",
       "    history_right  history_wrong      time  \n",
       "87       4.242641       1.000000  0.004132  \n",
       "88       4.472136       1.000000  0.004132  \n",
       "89       4.582576       1.414214  0.004132  \n",
       "90       6.082763       3.000000  0.004132  \n",
       "91       4.582576       1.414214  0.004132  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duolingo_dataset['history_right'] = duolingo_dataset.apply(lambda row: math.sqrt(1 + row['history_correct']), axis=1)\n",
    "duolingo_dataset['history_wrong'] = duolingo_dataset.apply(lambda row: math.sqrt(1 + row['history_seen'] - row['history_correct']), axis=1)\n",
    "duolingo_dataset['time'] = duolingo_dataset.apply(lambda row: row['delta']/(60*60*24), axis=1)\n",
    "duolingo_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-torture",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "improved-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "samples = len(duolingo_dataset)\n",
    "split_lengths = [int(samples*0.9), samples - int(samples*0.9)]\n",
    "X = duolingo_dataset[['history_right', 'history_wrong', 'time']]\n",
    "# X = duolingo_dataset[['history_right', 'history_wrong']] # HLR\n",
    "# X = duolingo_dataset[['time', 'history_correct', 'history_seen']]\n",
    "y = duolingo_dataset['p_recall']\n",
    "dataset = TensorDataset(torch.tensor(X.values, dtype=torch.float, device=device), torch.tensor(y.values, dtype=torch.float, device=device).unsqueeze(1))\n",
    "train, test = random_split(dataset, split_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "essential-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = TensorDataset(torch.tensor(X.values).float(), torch.tensor(y.values).float())\n",
    "# train, test = random_split(dataset, split_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-florist",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_hl = 15.0 / (24 * 60) # 15 minutes\n",
    "min_hl = 10.0 / (24 * 60) # 10 minutes\n",
    "# max_hl = 274.0\n",
    "max_hl = 1000.0\n",
    "min_hl_pow = math.log2(min_hl)\n",
    "max_hl_pow = math.log2(max_hl)\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "class SimpleNetSigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNetSigmoid, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.clamp(self.fc3(x), min=0, max=1)\n",
    "        return x\n",
    "\n",
    "class DeepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 30)\n",
    "        self.fc2 = nn.Linear(30, 30)\n",
    "        self.fc3 = nn.Linear(30, 30)\n",
    "        self.fc4 = nn.Linear(30, 30)\n",
    "        self.fc5 = nn.Linear(30, 30)\n",
    "        self.fc6 = nn.Linear(30, 30)\n",
    "        self.fc7 = nn.Linear(30, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = torch.clamp(self.fc7(x), min=0, max=1)\n",
    "        return x\n",
    "\n",
    "class HLRWithHNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HLRWithHNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        t = x[:, 2].unsqueeze(1)\n",
    "        x = torch.clamp(self.fc1(x), min_hl_pow, max_hl_pow)\n",
    "        h = torch.pow(2, x)\n",
    "        p = torch.pow(2, -t/h)\n",
    "        return p, h\n",
    "\n",
    "class HLRNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HLRNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.clamp(self.fc1(x), min_hl_pow, max_hl_pow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-laugh",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "incredible-december",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4513311 training samples among 70521 batches of size 64\n",
      "Epoch 1 loss 0.1111, accuracy 0.2993\n",
      "Epoch 1 loss 0.0998, accuracy 0.2885\n",
      "Epoch 1 loss 0.0998, accuracy 0.2885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([31, 1])) that is different to the input size (torch.Size([31, 30])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epoch 1 loss 0.1030, accuracy 0.2915\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-370-9f78446dae78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 3\n",
    "weight_decay = 0.1\n",
    "lr = 0.001\n",
    "alpha = 0.01\n",
    "# model = HLRWithHNet()\n",
    "model = DeepNet()\n",
    "model.to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.L1Loss()\n",
    "loss_fn.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "train_loader = DataLoader(train, batch_size=batch_size)\n",
    "test_loader = DataLoader(test, batch_size=batch_size)\n",
    "\n",
    "print(f'{len(train)} training samples among {len(train_loader)} batches of size {batch_size}')\n",
    "\n",
    "def accuracy(pred, y):\n",
    "    return torch.abs(pred - y).mean()\n",
    "\n",
    "epoch_loss, epoch_acc = 0, 0\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss, epoch_acc, running_loss, running_acc, batch_count = 0, 0, 0, 0, 0\n",
    "    batches = len(train_loader)\n",
    "    for batch in train_loader:\n",
    "        X, y = batch\n",
    "        optimizer.zero_grad()\n",
    "#         output, h = model(X)\n",
    "        output = model(X)\n",
    "        loss = loss_fn(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            acc = accuracy(output, y)\n",
    "            running_loss += loss.item()\n",
    "            running_acc += acc.item()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "        batch_count += 1\n",
    "        if batch_count % 19999 == 0:\n",
    "            print(f'Epoch {epoch+1} loss {running_loss/20000:.4f}, accuracy {running_acc/20000:.4f}')\n",
    "            running_loss = 0\n",
    "            running_acc = 0\n",
    "    print(f'Total epoch {epoch+1} loss {epoch_loss/batches:.4f}, accuracy {epoch_acc/batches:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-target",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "crazy-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hlr_loss_fn(alpha, y_hat, y, h_hat, h):\n",
    "    return ((y_hat - y).pow(2) + alpha*(h_hat - h).pow(2)).mean()\n",
    "\n",
    "def hlr_prediction(delta, log2h):\n",
    "    h = torch.pow(2, log2h)\n",
    "    neg_delta_over_h = -delta/h\n",
    "    return torch.pow(2, neg_delta_over_h)\n",
    "\n",
    "# def complete_hlr_loss_fn(delta, log2h, y):\n",
    "#     h = torch.pow(2, log2h)\n",
    "#     return (torch.pow(2, -delta/torch.pow(2, log2h)) - y).pow(2) + 0.01*(torch.pow(2, log2h) + delta/torch.log2(y)).pow(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-movement",
   "metadata": {},
   "source": [
    "## HLR Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "breeding-fishing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4513311 training samples among 70521 batches of size 64\n",
      "Total epoch 1 loss 640.6961, accuracy 0.2045\n",
      "Total epoch 2 loss 624.0540, accuracy 0.1377\n",
      "Total epoch 3 loss 624.0540, accuracy 0.1377\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 3\n",
    "weight_decay = 0.1\n",
    "lr = 0.001\n",
    "alpha = 0.01\n",
    "model = HLRWithHNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "train_loader = DataLoader(train, batch_size=batch_size)\n",
    "test_loader = DataLoader(test, batch_size=batch_size)\n",
    "\n",
    "print(f'{len(train)} training samples among {len(train_loader)} batches of size {batch_size}')\n",
    "\n",
    "def accuracy(pred, y):\n",
    "    return torch.abs(pred - y).mean()\n",
    "\n",
    "epoch_loss, epoch_acc = 0, 0\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss, epoch_acc, running_loss, running_acc, batch_count = 0, 0, 0, 0, 0\n",
    "    batches = len(train_loader)\n",
    "    for batch in train_loader:\n",
    "        X, y = batch\n",
    "        optimizer.zero_grad()\n",
    "#         log2h = model(X)\n",
    "        prediction, pred_h = model(X)\n",
    "#         print(f'h_hat: {h_hat.shape}')\n",
    "        delta = X[:, 2].unsqueeze(1)\n",
    "#         delta.detach()\n",
    "#         print(f'd: {delta.shape}')\n",
    "#         print(f'y: {y.shape}')\n",
    "        h = torch.where(y == 0, torch.tensor(max_hl, dtype=torch.float), (-delta/torch.log2(y)).clamp(min_hl, max_hl))\n",
    "#         h.detach()\n",
    "#         print(f'pred: {prediction}, pred_h: {pred_h}, delta: {delta}, h: {h}, y: {y}')\n",
    "        loss = hlr_loss_fn(alpha, prediction, y, pred_h, h)\n",
    "#         loss = hlr_loss_fn(alpha, hlr_prediction(delta, log2h), y, torch.pow(2, log2h), h)\n",
    "#         loss = complete_hlr_loss_fn(delta, log2h, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            acc = accuracy(prediction, y)\n",
    "            running_loss += loss.item()\n",
    "            running_acc += acc.item()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "        batch_count += 1\n",
    "        if batch_count % 19999 == 0:\n",
    "            #print(f'Epoch {epoch+1} loss {running_loss/20000:.4f}, accuracy {running_acc/20000:.4f}')\n",
    "            running_loss = 0\n",
    "            running_acc = 0\n",
    "    print(f'Total epoch {epoch+1} loss {epoch_loss/batches:.4f}, accuracy {epoch_acc/batches:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-ukraine",
   "metadata": {},
   "source": [
    "## LSTM Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "universal-benchmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM X shape: torch.Size([304411, 11, 3]), y shape: torch.Size([304411, 1])\n",
      "304411 samples\n",
      "Split lengths: [273969, 30442]\n"
     ]
    }
   ],
   "source": [
    "# for r in duolingo_dataset.groupby(['user_id', 'lexeme_id']).size()[:5]:\n",
    "#     print(r)\n",
    "# lstm_dataset = duolingo_dataset[['user_id', 'lexeme_id', 'timestamp', 'p_recall', 'delta']].sort_values(by=['user_id', 'lexeme_id', 'timestamp'])\n",
    "k = 11\n",
    "sequences = []\n",
    "labels = []\n",
    "# for row in lstm_dataset[:5].itertuples():\n",
    "#     if prev_user_lexeme == (row.user_id, row.lexeme_id):\n",
    "#         prev_p_deltas.append([row.p_recall, row.delta])\n",
    "# count = 0\n",
    "for (_, rows) in duolingo_dataset[['user_id', 'lexeme_id', 'timestamp', 'p_recall', 'time']].groupby(['user_id', 'lexeme_id']):\n",
    "    if len(rows) > k:\n",
    "        sequence = rows.sort_values(by=['timestamp'])[['p_recall', 'time']]\n",
    "        sequence['next_time'] = sequence['time'].shift(-1)\n",
    "        sequences.extend([sequence[i:i+k].values for i in range(len(sequence)-k)])\n",
    "        labels.extend(sequence['p_recall'].values[k:])\n",
    "#         count += 1\n",
    "#     if count == 2:\n",
    "#         break\n",
    "lstm_X = torch.tensor(sequences, dtype=torch.float)\n",
    "lstm_y = torch.tensor(labels, dtype=torch.float).unsqueeze(1)\n",
    "# print(lstm_X.shape)\n",
    "# print(lstm_X)\n",
    "# print(lstm_y.shape)\n",
    "# print(lstm_y)\n",
    "print(f'LSTM X shape: {lstm_X.shape}, y shape: {lstm_y.shape}')\n",
    "samples = len(sequences)\n",
    "print(f'{samples} samples')\n",
    "split_lengths = [int(samples*0.9), samples - int(samples*0.9)]\n",
    "print(f'Split lengths: {split_lengths}')\n",
    "lstm_dataset = TensorDataset(lstm_X, lstm_y)\n",
    "lstm_train_data, lstm_test_data = random_split(lstm_dataset, split_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-wheat",
   "metadata": {},
   "source": [
    "## LSTM Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "heavy-joshua",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss 0.0967, accuracy 0.2138\n",
      "Epoch 1 loss 0.0918, accuracy 0.2092\n",
      "Total epoch 1: loss 0.0941, accuracy 0.2113, mins 2, secs 11\n",
      "Epoch 2 loss 0.0911, accuracy 0.2079\n",
      "Epoch 2 loss 0.0917, accuracy 0.2092\n",
      "Total epoch 2: loss 0.0914, accuracy 0.2086, mins 2, secs 10\n",
      "Epoch 3 loss 0.0910, accuracy 0.2079\n",
      "Epoch 3 loss 0.0917, accuracy 0.2092\n",
      "Total epoch 3: loss 0.0913, accuracy 0.2086, mins 2, secs 14\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, features_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.LSTM(features_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "#         self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "    def forward(self, sequences):        \n",
    "        output, (hidden, cell) = self.rnn(sequences)\n",
    "#         hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "#         hidden = self.dropout(hidden[-1,:,:])\n",
    "        output = self.dropout(output)\n",
    "#         print(f'{output.shape} output, {hidden.shape} hidden, len seq {sequences.shape}')\n",
    "#         hidden = hidden.view(hidden.shape[0], len(sequences), self.hidden_dim)\n",
    "        output = output.view(output.shape[1], len(sequences), self.hidden_dim)[-1]\n",
    "#         output = output.view(output.shape[1]*2, len(sequences), self.hidden_dim)\n",
    "#         output = torch.cat((output[-2,:,:], output[-1,:,:]), dim = 1)\n",
    "#         return self.fc(hidden)\n",
    "        return self.fc(output)\n",
    "\n",
    "INPUT_DIM = 3 # p_recall, delta, next_delta\n",
    "HIDDEN_DIM = 32\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = False\n",
    "DROPOUT = 0.0\n",
    "lr = 0.001\n",
    "weight_decay = 0.0\n",
    "\n",
    "model = RNN(INPUT_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "lstm_optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "lstm_criterion = nn.MSELoss()\n",
    "model = model.to(device)\n",
    "lstm_criterion = lstm_criterion.to(device)\n",
    "\n",
    "def lstm_train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    running_loss, running_acc, batch_count = 0, 0, 0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        X, y = batch\n",
    "        predictions = model(X)\n",
    "        loss = criterion(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            acc = accuracy(predictions, y)\n",
    "            running_loss += loss.item()\n",
    "            running_acc += acc.item()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "        batch_count += 1\n",
    "        if batch_count % 1999 == 0:\n",
    "            print(f'Epoch {epoch+1} loss {running_loss/2000:.4f}, accuracy {running_acc/2000:.4f}')\n",
    "            running_loss = 0\n",
    "            running_acc = 0\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "lstm_train_loader = DataLoader(lstm_train_data, batch_size=batch_size)\n",
    "lstm_test_loader = DataLoader(lstm_test_data, batch_size=batch_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = lstm_train(model, lstm_train_loader, lstm_optimizer, lstm_criterion)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)    \n",
    "    # print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    # print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    print(f'Total epoch {epoch+1}: loss {train_loss:.4f}, accuracy {train_acc:.4f}, mins {epoch_mins}, secs {epoch_secs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-friend",
   "metadata": {},
   "source": [
    "## LSTM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "gorgeous-framework",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final testing loss 0.0918, accuracy 0.2053\n",
      "Average true p_recall: 0.8719, variance: 0.091716544858\n",
      "Average predicted p_recall: 0.8791, variance: 0.000001711210\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "ys = []\n",
    "\n",
    "def lstm_evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            X, y = batch\n",
    "            predictions = model(X)\n",
    "            loss = criterion(predictions, y)\n",
    "            acc = accuracy(predictions, y)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            preds.extend(predictions.squeeze(1).tolist())\n",
    "            ys.extend(y.squeeze(1).tolist())\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "lstm_test_loss, lstm_test_acc = lstm_evaluate(model, lstm_test_loader, lstm_criterion)\n",
    "print(f'Final testing loss {lstm_test_loss:.4f}, accuracy {lstm_test_acc:.4f}')\n",
    "with open('predictions.csv', 'w') as file:\n",
    "    for line in [f'{phat},{p}\\n' for phat, p in zip(preds, ys)]:\n",
    "        file.write(line)\n",
    "\n",
    "print(f'Average true p_recall: {sum(ys)/len(ys):.4f}, variance: {statistics.pvariance(ys):.12f}')\n",
    "print(f'Average predicted p_recall: {sum(preds)/len(preds):.4f}, variance: {statistics.pvariance(preds):.12f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "attempted-screening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average true p_recall: 0.8977, variance: 0.074783152983\n"
     ]
    }
   ],
   "source": [
    "# model(torch.tensor([[[1, 15, 80], [1, 80, 140], [1, 140, 8]]], dtype=torch.float))\n",
    "print(f'Average true p_recall: {sum(ys)/len(ys):.4f}, variance: {statistics.pvariance(ys):.12f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-bahrain",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "bottom-powder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression test loss: 0.0806, test acc: 0.1205\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            X, y = batch\n",
    "            predictions, h = model(X)\n",
    "#             predictions = model(X)\n",
    "            loss = criterion(predictions, y)\n",
    "            acc = accuracy(predictions, y)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_loader, loss_fn)\n",
    "print(f'Regression test loss: {test_loss:.4f}, test acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "altered-matter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average predicted p_recall: 0.9719\n",
      "Average true p_recall: 0.8977\n"
     ]
    }
   ],
   "source": [
    "total_p = 0\n",
    "total_y = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        X, y = batch\n",
    "        predictions, h = model(X)\n",
    "#         predictions = model(X)\n",
    "        total_p += predictions.sum()\n",
    "        total_y += y.sum()\n",
    "print(f'Average predicted p_recall: {total_p/len(test):.4f}')\n",
    "print(f'Average true p_recall: {total_y/len(test):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
