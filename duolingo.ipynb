{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "minor-glossary",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "adjacent-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "import time\n",
    "import math\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-african",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "upset-championship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_recall</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>delta</th>\n",
       "      <th>user_id</th>\n",
       "      <th>learning_language</th>\n",
       "      <th>ui_language</th>\n",
       "      <th>lexeme_id</th>\n",
       "      <th>lexeme_string</th>\n",
       "      <th>history_seen</th>\n",
       "      <th>history_correct</th>\n",
       "      <th>session_seen</th>\n",
       "      <th>session_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>1052c3ace653dbc8923eaa183bc02b88</td>\n",
       "      <td>definition/definition&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>9cba1b30f88bf3c047b22cffcaf88c12</td>\n",
       "      <td>surface/surface&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>961cd149f20f2571419b1412d849f19a</td>\n",
       "      <td>scale/scale&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>5cbb1249562e95794a4c4ae0e2d8ae26</td>\n",
       "      <td>temperature/temperature&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>44</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>2df65bdf80d10d2b78d62cb2e0a731d8</td>\n",
       "      <td>distance/distance&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p_recall   timestamp  delta user_id learning_language ui_language  \\\n",
       "87       1.0  1362082504    357  u:dwbJ                en          pt   \n",
       "88       1.0  1362082504    357  u:dwbJ                en          pt   \n",
       "89       1.0  1362082504    357  u:dwbJ                en          pt   \n",
       "90       0.8  1362082504    357  u:dwbJ                en          pt   \n",
       "91       1.0  1362082504    357  u:dwbJ                en          pt   \n",
       "\n",
       "                           lexeme_id                   lexeme_string  \\\n",
       "87  1052c3ace653dbc8923eaa183bc02b88    definition/definition<n><sg>   \n",
       "88  9cba1b30f88bf3c047b22cffcaf88c12          surface/surface<n><sg>   \n",
       "89  961cd149f20f2571419b1412d849f19a              scale/scale<n><sg>   \n",
       "90  5cbb1249562e95794a4c4ae0e2d8ae26  temperature/temperature<n><sg>   \n",
       "91  2df65bdf80d10d2b78d62cb2e0a731d8        distance/distance<n><sg>   \n",
       "\n",
       "    history_seen  history_correct  session_seen  session_correct  \n",
       "87            17               17             2                2  \n",
       "88            19               19             3                3  \n",
       "89            21               20             3                3  \n",
       "90            44               36             5                4  \n",
       "91            21               20             3                3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duolingo_dataset = pd.read_csv(\"./settles.acl16.learning_traces.13m.csv\")\n",
    "duolingo_dataset = duolingo_dataset[duolingo_dataset[\"learning_language\"] == \"en\"]\n",
    "duolingo_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-sheet",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "immune-potter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_recall</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>delta</th>\n",
       "      <th>user_id</th>\n",
       "      <th>learning_language</th>\n",
       "      <th>ui_language</th>\n",
       "      <th>lexeme_id</th>\n",
       "      <th>lexeme_string</th>\n",
       "      <th>history_seen</th>\n",
       "      <th>history_correct</th>\n",
       "      <th>session_seen</th>\n",
       "      <th>session_correct</th>\n",
       "      <th>history_right</th>\n",
       "      <th>history_wrong</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>1052c3ace653dbc8923eaa183bc02b88</td>\n",
       "      <td>definition/definition&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>9cba1b30f88bf3c047b22cffcaf88c12</td>\n",
       "      <td>surface/surface&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>961cd149f20f2571419b1412d849f19a</td>\n",
       "      <td>scale/scale&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.582576</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.004132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>5cbb1249562e95794a4c4ae0e2d8ae26</td>\n",
       "      <td>temperature/temperature&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>44</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6.082763</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.004132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362082504</td>\n",
       "      <td>357</td>\n",
       "      <td>u:dwbJ</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "      <td>2df65bdf80d10d2b78d62cb2e0a731d8</td>\n",
       "      <td>distance/distance&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.582576</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.004132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p_recall   timestamp  delta user_id learning_language ui_language  \\\n",
       "87       1.0  1362082504    357  u:dwbJ                en          pt   \n",
       "88       1.0  1362082504    357  u:dwbJ                en          pt   \n",
       "89       1.0  1362082504    357  u:dwbJ                en          pt   \n",
       "90       0.8  1362082504    357  u:dwbJ                en          pt   \n",
       "91       1.0  1362082504    357  u:dwbJ                en          pt   \n",
       "\n",
       "                           lexeme_id                   lexeme_string  \\\n",
       "87  1052c3ace653dbc8923eaa183bc02b88    definition/definition<n><sg>   \n",
       "88  9cba1b30f88bf3c047b22cffcaf88c12          surface/surface<n><sg>   \n",
       "89  961cd149f20f2571419b1412d849f19a              scale/scale<n><sg>   \n",
       "90  5cbb1249562e95794a4c4ae0e2d8ae26  temperature/temperature<n><sg>   \n",
       "91  2df65bdf80d10d2b78d62cb2e0a731d8        distance/distance<n><sg>   \n",
       "\n",
       "    history_seen  history_correct  session_seen  session_correct  \\\n",
       "87            17               17             2                2   \n",
       "88            19               19             3                3   \n",
       "89            21               20             3                3   \n",
       "90            44               36             5                4   \n",
       "91            21               20             3                3   \n",
       "\n",
       "    history_right  history_wrong      time  \n",
       "87       4.242641       1.000000  0.004132  \n",
       "88       4.472136       1.000000  0.004132  \n",
       "89       4.582576       1.414214  0.004132  \n",
       "90       6.082763       3.000000  0.004132  \n",
       "91       4.582576       1.414214  0.004132  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duolingo_dataset['history_right'] = duolingo_dataset.apply(lambda row: math.sqrt(1 + row['history_correct']), axis=1)\n",
    "duolingo_dataset['history_wrong'] = duolingo_dataset.apply(lambda row: math.sqrt(1 + row['history_seen'] - row['history_correct']), axis=1)\n",
    "duolingo_dataset['time'] = duolingo_dataset.apply(lambda row: row['delta']/(60*60*24), axis=1)\n",
    "duolingo_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-section",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "alert-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = len(duolingo_dataset)\n",
    "split_lengths = [int(samples*0.9), samples - int(samples*0.9)]\n",
    "X = duolingo_dataset[['history_right', 'history_wrong', 'time']]\n",
    "# X = duolingo_dataset[['history_right', 'history_wrong']] # HLR\n",
    "# X = duolingo_dataset[['time', 'history_correct', 'history_seen']]\n",
    "y = duolingo_dataset['p_recall']\n",
    "dataset = TensorDataset(torch.tensor(X.values).float(), torch.tensor(y.values).float().unsqueeze(1))\n",
    "train, test = random_split(dataset, split_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "maritime-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = TensorDataset(torch.tensor(X.values).float(), torch.tensor(y.values).float())\n",
    "# train, test = random_split(dataset, split_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-navigation",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "bizarre-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_hl = 15.0 / (24 * 60) # 15 minutes\n",
    "min_hl = 10.0 / (24 * 60) # 10 minutes\n",
    "# max_hl = 274.0\n",
    "max_hl = 1000.0\n",
    "min_hl_pow = math.log2(min_hl)\n",
    "max_hl_pow = math.log2(max_hl)\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "class SimpleNetSigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNetSigmoid, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.clamp(self.fc3(x), min=0, max=1)\n",
    "        return x\n",
    "\n",
    "class HLRWithHNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HLRWithHNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        t = x[:, 2].unsqueeze(1)\n",
    "        x = torch.clamp(self.fc1(x), min_hl_pow, max_hl_pow)\n",
    "        h = torch.pow(2, x)\n",
    "        p = torch.pow(2, -t/h)\n",
    "        return p, h\n",
    "\n",
    "class HLRNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HLRNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.clamp(self.fc1(x), min_hl_pow, max_hl_pow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-driving",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "damaged-somewhere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4513311 training samples among 70521 batches of size 64\n",
      "Total epoch 1 loss 0.0741, accuracy 0.1997\n",
      "Total epoch 2 loss 0.0735, accuracy 0.2006\n",
      "Total epoch 3 loss 0.0735, accuracy 0.2006\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 3\n",
    "weight_decay = 0.1\n",
    "lr = 0.001\n",
    "alpha = 0.01\n",
    "# model = HLRWithHNet()\n",
    "model = LinearNet()\n",
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "train_loader = DataLoader(train, batch_size=batch_size)\n",
    "test_loader = DataLoader(test, batch_size=batch_size)\n",
    "\n",
    "print(f'{len(train)} training samples among {len(train_loader)} batches of size {batch_size}')\n",
    "\n",
    "def accuracy(pred, y):\n",
    "    return torch.abs(pred - y).mean()\n",
    "\n",
    "epoch_loss, epoch_acc = 0, 0\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss, epoch_acc, running_loss, running_acc, batch_count = 0, 0, 0, 0, 0\n",
    "    batches = len(train_loader)\n",
    "    for batch in train_loader:\n",
    "        X, y = batch\n",
    "        optimizer.zero_grad()\n",
    "#         output, h = model(X)\n",
    "        output = model(X)\n",
    "        loss = loss_fn(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            acc = accuracy(output, y)\n",
    "            running_loss += loss.item()\n",
    "            running_acc += acc.item()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "        batch_count += 1\n",
    "        if batch_count % 19999 == 0:\n",
    "            #print(f'Epoch {epoch+1} loss {running_loss/20000:.4f}, accuracy {running_acc/20000:.4f}')\n",
    "            running_loss = 0\n",
    "            running_acc = 0\n",
    "    print(f'Total epoch {epoch+1} loss {epoch_loss/batches:.4f}, accuracy {epoch_acc/batches:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-leadership",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "empirical-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hlr_loss_fn(alpha, y_hat, y, h_hat, h):\n",
    "    return ((y_hat - y).pow(2) + alpha*(h_hat - h).pow(2)).mean()\n",
    "\n",
    "def hlr_prediction(delta, log2h):\n",
    "    h = torch.pow(2, log2h)\n",
    "    neg_delta_over_h = -delta/h\n",
    "    return torch.pow(2, neg_delta_over_h)\n",
    "\n",
    "# def complete_hlr_loss_fn(delta, log2h, y):\n",
    "#     h = torch.pow(2, log2h)\n",
    "#     return (torch.pow(2, -delta/torch.pow(2, log2h)) - y).pow(2) + 0.01*(torch.pow(2, log2h) + delta/torch.log2(y)).pow(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-priority",
   "metadata": {},
   "source": [
    "## HLR Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "endangered-artwork",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4513311 training samples among 70521 batches of size 64\n",
      "Total epoch 1 loss 640.6961, accuracy 0.2045\n",
      "Total epoch 2 loss 624.0540, accuracy 0.1377\n",
      "Total epoch 3 loss 624.0540, accuracy 0.1377\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 3\n",
    "weight_decay = 0.1\n",
    "lr = 0.001\n",
    "alpha = 0.01\n",
    "model = HLRWithHNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "train_loader = DataLoader(train, batch_size=batch_size)\n",
    "test_loader = DataLoader(test, batch_size=batch_size)\n",
    "\n",
    "print(f'{len(train)} training samples among {len(train_loader)} batches of size {batch_size}')\n",
    "\n",
    "def accuracy(pred, y):\n",
    "    return torch.abs(pred - y).mean()\n",
    "\n",
    "epoch_loss, epoch_acc = 0, 0\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss, epoch_acc, running_loss, running_acc, batch_count = 0, 0, 0, 0, 0\n",
    "    batches = len(train_loader)\n",
    "    for batch in train_loader:\n",
    "        X, y = batch\n",
    "        optimizer.zero_grad()\n",
    "#         log2h = model(X)\n",
    "        prediction, pred_h = model(X)\n",
    "#         print(f'h_hat: {h_hat.shape}')\n",
    "        delta = X[:, 2].unsqueeze(1)\n",
    "#         delta.detach()\n",
    "#         print(f'd: {delta.shape}')\n",
    "#         print(f'y: {y.shape}')\n",
    "        h = torch.where(y == 0, torch.tensor(max_hl, dtype=torch.float), (-delta/torch.log2(y)).clamp(min_hl, max_hl))\n",
    "#         h.detach()\n",
    "#         print(f'pred: {prediction}, pred_h: {pred_h}, delta: {delta}, h: {h}, y: {y}')\n",
    "        loss = hlr_loss_fn(alpha, prediction, y, pred_h, h)\n",
    "#         loss = hlr_loss_fn(alpha, hlr_prediction(delta, log2h), y, torch.pow(2, log2h), h)\n",
    "#         loss = complete_hlr_loss_fn(delta, log2h, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            acc = accuracy(prediction, y)\n",
    "            running_loss += loss.item()\n",
    "            running_acc += acc.item()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "        batch_count += 1\n",
    "        if batch_count % 19999 == 0:\n",
    "            #print(f'Epoch {epoch+1} loss {running_loss/20000:.4f}, accuracy {running_acc/20000:.4f}')\n",
    "            running_loss = 0\n",
    "            running_acc = 0\n",
    "    print(f'Total epoch {epoch+1} loss {epoch_loss/batches:.4f}, accuracy {epoch_acc/batches:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-stations",
   "metadata": {},
   "source": [
    "## LSTM Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "independent-rochester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM X shape: torch.Size([1395552, 3, 3]), y shape: torch.Size([1395552, 1])\n",
      "1395552 samples\n",
      "Split lengths: [1255996, 139556]\n"
     ]
    }
   ],
   "source": [
    "# for r in duolingo_dataset.groupby(['user_id', 'lexeme_id']).size()[:5]:\n",
    "#     print(r)\n",
    "# lstm_dataset = duolingo_dataset[['user_id', 'lexeme_id', 'timestamp', 'p_recall', 'delta']].sort_values(by=['user_id', 'lexeme_id', 'timestamp'])\n",
    "k = 3\n",
    "sequences = []\n",
    "labels = []\n",
    "# for row in lstm_dataset[:5].itertuples():\n",
    "#     if prev_user_lexeme == (row.user_id, row.lexeme_id):\n",
    "#         prev_p_deltas.append([row.p_recall, row.delta])\n",
    "# count = 0\n",
    "for (_, rows) in duolingo_dataset[['user_id', 'lexeme_id', 'timestamp', 'p_recall', 'time']].groupby(['user_id', 'lexeme_id']):\n",
    "    if len(rows) > k:\n",
    "        sequence = rows.sort_values(by=['timestamp'])[['p_recall', 'time']]\n",
    "        sequence['next_time'] = sequence['time'].shift(-1)\n",
    "        sequences.extend([sequence[i:i+k].values for i in range(len(sequence)-k)])\n",
    "        labels.extend(sequence['p_recall'].values[k:])\n",
    "#         count += 1\n",
    "#     if count == 2:\n",
    "#         break\n",
    "lstm_X = torch.tensor(sequences, dtype=torch.float)\n",
    "lstm_y = torch.tensor(labels, dtype=torch.float).unsqueeze(1)\n",
    "# print(lstm_X.shape)\n",
    "# print(lstm_X)\n",
    "# print(lstm_y.shape)\n",
    "# print(lstm_y)\n",
    "print(f'LSTM X shape: {lstm_X.shape}, y shape: {lstm_y.shape}')\n",
    "samples = len(sequences)\n",
    "print(f'{samples} samples')\n",
    "split_lengths = [int(samples*0.9), samples - int(samples*0.9)]\n",
    "print(f'Split lengths: {split_lengths}')\n",
    "lstm_dataset = TensorDataset(lstm_X, lstm_y)\n",
    "lstm_train_data, lstm_test_data = random_split(lstm_dataset, split_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-smell",
   "metadata": {},
   "source": [
    "## LSTM Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "headed-olympus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss 0.0827, accuracy 0.1835\n",
      "Epoch 1 loss 0.0762, accuracy 0.1766\n",
      "Epoch 1 loss 0.0746, accuracy 0.1736\n",
      "Epoch 1 loss 0.0750, accuracy 0.1745\n",
      "Epoch 1 loss 0.0751, accuracy 0.1744\n",
      "Epoch 1 loss 0.0747, accuracy 0.1734\n",
      "Epoch 1 loss 0.0748, accuracy 0.1737\n",
      "Epoch 1 loss 0.0746, accuracy 0.1738\n",
      "Epoch 1 loss 0.0737, accuracy 0.1719\n",
      "Total epoch 1: loss 0.0757, accuracy 0.1750, mins 8, secs 47\n",
      "Epoch 2 loss 0.0751, accuracy 0.1744\n",
      "Epoch 2 loss 0.0761, accuracy 0.1765\n",
      "Epoch 2 loss 0.0746, accuracy 0.1736\n",
      "Epoch 2 loss 0.0749, accuracy 0.1744\n",
      "Epoch 2 loss 0.0751, accuracy 0.1744\n",
      "Epoch 2 loss 0.0746, accuracy 0.1734\n",
      "Epoch 2 loss 0.0747, accuracy 0.1737\n",
      "Epoch 2 loss 0.0746, accuracy 0.1737\n",
      "Epoch 2 loss 0.0737, accuracy 0.1719\n",
      "Total epoch 2: loss 0.0749, accuracy 0.1741, mins 8, secs 22\n",
      "Epoch 3 loss 0.0751, accuracy 0.1744\n",
      "Epoch 3 loss 0.0761, accuracy 0.1765\n",
      "Epoch 3 loss 0.0746, accuracy 0.1736\n",
      "Epoch 3 loss 0.0749, accuracy 0.1744\n",
      "Epoch 3 loss 0.0750, accuracy 0.1744\n",
      "Epoch 3 loss 0.0746, accuracy 0.1733\n",
      "Epoch 3 loss 0.0747, accuracy 0.1736\n",
      "Epoch 3 loss 0.0746, accuracy 0.1737\n",
      "Epoch 3 loss 0.0737, accuracy 0.1718\n",
      "Total epoch 3: loss 0.0748, accuracy 0.1741, mins 8, secs 20\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, features_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.LSTM(features_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "#         self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "    def forward(self, sequences):        \n",
    "        output, (hidden, cell) = self.rnn(sequences)\n",
    "#         hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "#         hidden = self.dropout(hidden[-1,:,:])\n",
    "        output = self.dropout(output)\n",
    "#         print(f'{output.shape} output, {hidden.shape} hidden, len seq {sequences.shape}')\n",
    "#         hidden = hidden.view(hidden.shape[0], len(sequences), self.hidden_dim)\n",
    "        output = output.view(output.shape[1], len(sequences), self.hidden_dim)[-1]\n",
    "#         return self.fc(hidden)\n",
    "        return self.fc(output)\n",
    "\n",
    "INPUT_DIM = 3 # p_recall, delta, next_delta\n",
    "HIDDEN_DIM = 16\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = False#True\n",
    "DROPOUT = 0.0\n",
    "\n",
    "model = RNN(INPUT_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "lstm_optimizer = optim.Adam(model.parameters())\n",
    "lstm_criterion = nn.MSELoss()\n",
    "model = model.to(device)\n",
    "lstm_criterion = lstm_criterion.to(device)\n",
    "\n",
    "def lstm_train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    running_loss, running_acc, batch_count = 0, 0, 0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        X, y = batch\n",
    "        predictions = model(X)\n",
    "        loss = criterion(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            acc = accuracy(predictions, y)\n",
    "            running_loss += loss.item()\n",
    "            running_acc += acc.item()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "        batch_count += 1\n",
    "        if batch_count % 1999 == 0:\n",
    "            print(f'Epoch {epoch+1} loss {running_loss/2000:.4f}, accuracy {running_acc/2000:.4f}')\n",
    "            running_loss = 0\n",
    "            running_acc = 0\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "lstm_train_loader = DataLoader(lstm_train_data, batch_size=batch_size)\n",
    "lstm_test_loader = DataLoader(lstm_test_data, batch_size=batch_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = lstm_train(model, lstm_train_loader, lstm_optimizer, lstm_criterion)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)    \n",
    "    # print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    # print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    # print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    print(f'Total epoch {epoch+1}: loss {train_loss:.4f}, accuracy {train_acc:.4f}, mins {epoch_mins}, secs {epoch_secs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-guest",
   "metadata": {},
   "source": [
    "## LSTM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "authorized-arthritis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final testing loss 0.0753, accuracy 0.1585\n",
      "Average true p_recall: 0.8977, variance: 0.074783152983\n",
      "Average predicted p_recall: 0.9201, variance: 0.000009352349\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "ys = []\n",
    "\n",
    "def lstm_evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            X, y = batch\n",
    "            predictions = model(X)\n",
    "            loss = criterion(predictions, y)\n",
    "            acc = accuracy(predictions, y)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            preds.extend(predictions.squeeze(1).tolist())\n",
    "            ys.extend(y.squeeze(1).tolist())\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "lstm_test_loss, lstm_test_acc = lstm_evaluate(model, lstm_test_loader, lstm_criterion)\n",
    "print(f'Final testing loss {lstm_test_loss:.4f}, accuracy {lstm_test_acc:.4f}')\n",
    "with open('predictions.csv', 'w') as file:\n",
    "    for line in [f'{phat},{p}\\n' for phat, p in zip(preds, ys)]:\n",
    "        file.write(line)\n",
    "\n",
    "print(f'Average true p_recall: {sum(ys)/len(ys):.4f}, variance: {statistics.pvariance(ys):.12f}')\n",
    "print(f'Average predicted p_recall: {sum(preds)/len(preds):.4f}, variance: {statistics.pvariance(preds):.12f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "right-minute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average true p_recall: 0.8977, variance: 0.074783152983\n"
     ]
    }
   ],
   "source": [
    "# model(torch.tensor([[[1, 15, 80], [1, 80, 140], [1, 140, 8]]], dtype=torch.float))\n",
    "print(f'Average true p_recall: {sum(ys)/len(ys):.4f}, variance: {statistics.pvariance(ys):.12f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-wings",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "instant-angola",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression test loss: 0.0806, test acc: 0.1205\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            X, y = batch\n",
    "            predictions, h = model(X)\n",
    "#             predictions = model(X)\n",
    "            loss = criterion(predictions, y)\n",
    "            acc = accuracy(predictions, y)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_loader, loss_fn)\n",
    "print(f'Regression test loss: {test_loss:.4f}, test acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "armed-methodology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average predicted p_recall: 0.9719\n",
      "Average true p_recall: 0.8977\n"
     ]
    }
   ],
   "source": [
    "total_p = 0\n",
    "total_y = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        X, y = batch\n",
    "        predictions, h = model(X)\n",
    "#         predictions = model(X)\n",
    "        total_p += predictions.sum()\n",
    "        total_y += y.sum()\n",
    "print(f'Average predicted p_recall: {total_p/len(test):.4f}')\n",
    "print(f'Average true p_recall: {total_y/len(test):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
